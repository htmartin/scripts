03_introduction_to_apache_kafka
Architect and Build Big Data Applications
Introduction to Apache Kafka



Question 1 

What is Kafka?
*A messaging system???
*Publish - subscribe
*Distributed
Does not support batch consumers.

*Kafka provides a distributed publish - subscribe messaging system which enables communication and integration between components of large software systems.
For incorrect one:
Kafka does support batch consumers.


Question 2 
How does it enable processing big data?

*Helps to get data into Hadoop quickly.
*Supports scaling systems.
*Helps prevent data loss.
Gwen: "- not a drop in for anything JMS, diff apis and semantics"

?I would really like a good distractor here.  ? See https://aws.amazon.com/kinesis/streams/faqs/
When should I use Amazon Kinesis Streams, and when should I use Amazon SQS?

*A single Kafka broker can handle hundreds of megabytes of reads and writes per second from thousands of clients.
*Kafka can be elastically and transparently expanded without downtime. 
*Messages are persisted on disk and replicated within the cluster to prevent data loss. 
?  ?
Gwen: "- not a drop in for anything JMS, diff apis and semantics"

Question 3 

What are the key features of the tradeoffs for different Kafka consumers?

*Level of control vs. level of "automation" (word)
Some work well with relational data stores and others with streaming data.

*High level consumers allow less control but do more work, simple consumers allow more control but do less work, and new consumers are balanced in control and amount of work.
[Check caps]

Question 4. 

What are the benefits of unclean leader election?

*Downtime is minimized.
Consistency is maintained.
Chances of data loss are minimized.
It is easier than lass leader election.

*,~*,~*
???New (this said unclean???) leader election minimizes down time at the cost of being inconsistent and possibly actually losing data.
Configuration guides the choice of type of leader election, options are comparable on complexity.


_______________________________________________________________________________________________
Question 4 notes

If leader dies, unclean leader election (bc not in sync when became leader) - 1st node up is new leader - this is good bc it minimizes the down time, at cost of being inconsistent (nodes don't match) or actually losing data
Or wait until the last leader is back - this gives clean leader election but takes longer, do if OK waiting, so less availability, but more consistency
Decide based on configuration

***What do you do if a leader dies? 
correct options above
have distractors about take it all downn and start over
_______________________________________________________________________________________________

Question 3 notes

High level consumer
Tracks which offsets were read in Zookeeper or Kafka
Automatically balances partitions between threads or processes

Simple consumer
Low level API (called simple bc it's a simple API - not easy to use, just doens't do much)
Allows more control over how data is tracked and read
Requires attention to low level details (i.e., stuff like how data is tracked and read as opposed to doing that automatically)

New consumer
balance bt giving you more control and doing more work
Automatically handle failures and balance partitions
Can choose bt automatic and manual offset management

*Question about tradeoffs between these consumers
_______________________________________________________________________________________________


Question 2 Notes

Diff b/t Kenisis and SQS? Kafka not a message cue
Gwen: "- not a drop in for anything JMS, diff apis and semantics"

?I would really like a good distractor here.  ? See https://aws.amazon.com/kinesis/streams/faqs/
When should I use Amazon Kinesis Streams, and when should I use Amazon SQS?


Fast
A single Kafka broker can handle hundreds of megabytes of reads and writes per second from thousands of clients.

Scalable
Kafka is designed to allow a single cluster to serve as the central data backbone for a large organization. It can be elastically and transparently expanded without downtime. Data streams are partitioned and spread over a cluster of machines to allow data streams larger than the capability of any single machine and to allow clusters of co-ordinated consumers

Durable
Messages are persisted on disk and replicated within the cluster to prevent data loss. Each broker can handle terabytes of messages without performance impact.

Distributed by Design
Kafka has a modern cluster-centric design that offers strong durability and fault-tolerance guarantees.

